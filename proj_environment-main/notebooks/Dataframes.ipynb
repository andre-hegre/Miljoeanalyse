{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Her skal vi undersøke dataen hentet og bruke Pandas/SQL for å forstå strukturen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Her begynner vi med å forstå dataen fra frost bedre, og gjøre det om til en pandas dataframe, slik at det blir lett å jobbe med videre. \n",
    "\n",
    "I tillegg skal vi se på hvordan vi kan bruke pandasql (sqldf) for å gjøre querys på dataen og filtrere gjennom lettvint. Vi begynner med å hente file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import os\n",
    "\n",
    "# Henter file path\n",
    "\n",
    "notebook_directory = os.getcwd()\n",
    "root = os.path.abspath(os.path.join(notebook_directory, \"..\"))\n",
    "file_path = os.path.join(root, \"data\", \"Frost_Observations.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataen vi hentet er laget med mange dictionaries, som igjen inneholder flere dictionaries. For å kun få ut relevant data kan vi filtrere gjennom python for enkelte \"entries\" i forskjellige dictionaries. Deretter kan vi gjøre det om til en dataframe ved bruk av pandas og se hvordan dataen ser ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       elementId   sourceId             referenceTime  value     unit\n",
      "0    mean(relative_humidity P1D)  SN18700:0  2020-04-01T00:00:00.000Z   56.0  percent\n",
      "1  sum(precipitation_amount P1D)  SN18700:0  2020-04-01T00:00:00.000Z    0.0       mm\n",
      "2  sum(precipitation_amount P1D)  SN18700:0  2020-04-01T00:00:00.000Z    0.0       mm\n",
      "3           mean(wind_speed P1D)  SN18700:0  2020-04-01T00:00:00.000Z    2.6      m/s\n",
      "4      mean(air_temperature P1D)  SN18700:0  2020-04-01T00:00:00.000Z    6.4     degC\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_path,\"r\") as fil: #leser filen og lagrer den som \"data\"\n",
    "    data=json.load(fil)\n",
    "\n",
    "# filtrerer dataen for bare det som er relevant til å analysere\n",
    "brukbar_data = [\n",
    "    {\n",
    "        \"elementId\": obs[\"elementId\"],\n",
    "        \"sourceId\": entry[\"sourceId\"],\n",
    "        \"referenceTime\": entry[\"referenceTime\"],\n",
    "        \"value\": obs[\"value\"],\n",
    "        \"unit\": obs[\"unit\"]\n",
    "    }\n",
    "    for entry in data[\"data\"]\n",
    "    for obs in entry[\"observations\"] \n",
    "]\n",
    "\n",
    "df=pd.DataFrame(brukbar_data) #Dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None) #justerer output display\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da har vi fått lagd en dataframe med pandas som viser relevant data. Det ser litt uryddig ut og det passer bedre å ha hver observasjon som kolonner og så verdiene nedover, så vi kan bruke pd.pivot til til å gjøre det mer ryddig. \n",
    "\n",
    "Men det at vi har 2 verdier for mean(air_temperature P1D) og for sum(precipitation_amount P1D) gjør at dette ikke fungerer. Foreløpig kan vi kombinere det ved å ta gjennomsnittsverdien av de 2 målte, slik at vi kan visualisere dataframen bedre. Vi kan bruke \"groupby\" funksjonen for å samle de 2 identiske elementene og slå sammen verdiene med gjennomsnittet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elementId             referenceTime  mean(air_temperature P1D)  mean(relative_humidity P1D)  mean(wind_speed P1D)  sum(precipitation_amount P1D)\n",
      "0          2020-04-01T00:00:00.000Z                       6.15                         56.0                   2.6                           0.00\n",
      "1          2020-04-02T00:00:00.000Z                       4.75                         63.0                   4.7                           0.35\n",
      "2          2020-04-03T00:00:00.000Z                       3.60                         36.0                   4.3                           0.35\n",
      "3          2020-04-04T00:00:00.000Z                       2.90                         49.0                   3.4                           0.00\n",
      "4          2020-04-05T00:00:00.000Z                       4.65                         90.0                   1.9                           1.10\n"
     ]
    }
   ],
   "source": [
    "rader=[]\n",
    "\n",
    "# henter relevant data ved å iterere gjennom i forskjellige dictionaries\n",
    "for entry in data[\"data\"]:\n",
    "    referenceTime = entry[\"referenceTime\"]\n",
    "    for obs in entry[\"observations\"]:\n",
    "         rader.append({\n",
    "            \"referenceTime\": referenceTime,\n",
    "            \"elementId\": obs[\"elementId\"],\n",
    "            \"value\": obs[\"value\"],\n",
    "        })\n",
    "         \n",
    "df=pd.DataFrame(rader) #dataframe\n",
    "\n",
    "# slår sammen der det er 2 av mean(air_temperature P1D) og tar gjennomsnittet, \n",
    "# gjør pivot av dataframe, slik at kolonnene blir type observasjon\n",
    "\n",
    "df_gruppering = df.groupby([\"referenceTime\", \"elementId\"], as_index=False)[\"value\"].mean()\n",
    "df2=df_gruppering.pivot(index=\"referenceTime\",columns=\"elementId\",values=\"value\")\n",
    "df2=df2.reset_index()\n",
    "print(df2.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagrer df2 som json fil for videre bruk\n",
    "df2.to_json('../data/df2_data.json',indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her ser vi dataen på en mer forståelig måte. Det er verdt å merke at \"boolean_clear_sky_weather(cloud_area_fraction P1D)\" er boolean verdier, så i datahåndteringen kan vi ta hensyn til det og omgjøre det fra float. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bruker PANDAS SQL (sqldf) til å hente data fra DataFrame\n",
    "\n",
    "Nå som vi har en fungerende DataFrame, kan vi hente diverse type data og spesifikk data ved bruk av Pandas SQL/sqldf: \n",
    "\n",
    "1) Gjennomsnittlig temperatur for Juli i årene tilgjengelig\n",
    "2) Alle dager der 24 timers gjennomsnittstemperaturen er over 20 grader og der det ikke var skyete basert på \"boolean_clear_sky_weather...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     År  avg_temperatur_juli\n",
      "0  2020            14.993548\n",
      "1  2021            19.930645\n",
      "2  2022            17.524194\n",
      "3  2023            16.337097\n",
      "4  2024            16.812903\n"
     ]
    }
   ],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "    SELECT strftime('%Y',referenceTime) AS År,\n",
    "    AVG(\"mean(air_temperature P1D)\") AS avg_temperatur_juli\n",
    "    FROM df2\n",
    "    WHERE strftime('%m',referenceTime) = '07'\n",
    "    GROUP BY År\n",
    "\"\"\"\n",
    "resultat=pysqldf(query)\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her har vi for hele tidsperioden vi har i flere år:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month  avg_temperature\n",
      "0   2020-04         7.338333\n",
      "1   2020-05        10.000000\n",
      "2   2020-06        18.853333\n",
      "3   2020-07        14.993548\n",
      "4   2021-04         5.673333\n",
      "5   2021-05        10.430645\n",
      "6   2021-06        17.291667\n",
      "7   2021-07        19.930645\n",
      "8   2022-04         6.256667\n",
      "9   2022-05        11.390323\n",
      "10  2022-06        16.585000\n",
      "11  2022-07        17.524194\n",
      "12  2023-04         5.981667\n",
      "13  2023-05        11.830645\n",
      "14  2023-06        18.948333\n",
      "15  2023-07        16.337097\n",
      "16  2024-04         5.673333\n",
      "17  2024-05        16.025806\n",
      "18  2024-06        15.316667\n",
      "19  2024-07        16.812903\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT strftime('%Y-%m', referenceTime) AS Month, \n",
    "           AVG(\"mean(air_temperature P1D)\") AS avg_temperature\n",
    "    FROM df2\n",
    "    GROUP BY Month\n",
    "    ORDER BY Month;\n",
    "\"\"\"\n",
    "result = sqldf(query, globals())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               referenceTime  mean(air_temperature P1D)  mean(relative_humidity P1D)  mean(wind_speed P1D)  sum(precipitation_amount P1D)\n",
      "0   2023-06-17T00:00:00.000Z                      24.60                         36.0                   1.9                           0.00\n",
      "1   2020-06-19T00:00:00.000Z                      24.15                         49.0                   2.7                           0.00\n",
      "2   2023-06-16T00:00:00.000Z                      24.00                         43.0                   2.2                           0.00\n",
      "3   2023-06-15T00:00:00.000Z                      23.55                         44.0                   1.7                           0.00\n",
      "4   2020-06-27T00:00:00.000Z                      23.50                         59.0                   1.8                           0.05\n",
      "5   2020-06-20T00:00:00.000Z                      23.35                         63.0                   3.2                           0.25\n",
      "6   2020-06-16T00:00:00.000Z                      23.30                         51.0                   3.0                           0.30\n",
      "7   2021-07-25T00:00:00.000Z                      22.85                         50.0                   2.2                           0.00\n",
      "8   2021-07-26T00:00:00.000Z                      22.80                         57.0                   3.4                           0.10\n",
      "9   2021-07-03T00:00:00.000Z                      22.75                         43.0                   2.1                           0.20\n",
      "10  2021-07-16T00:00:00.000Z                      22.75                         54.0                   3.0                           0.10\n",
      "11  2021-07-14T00:00:00.000Z                      22.70                         74.0                   2.9                           1.05\n",
      "12  2023-06-18T00:00:00.000Z                      22.45                         60.0                   3.5                           0.25\n",
      "13  2021-07-04T00:00:00.000Z                      22.40                         70.0                   2.2                           4.35\n",
      "14  2020-06-18T00:00:00.000Z                      22.25                         56.0                   1.8                           0.00\n",
      "15  2021-07-15T00:00:00.000Z                      22.10                         63.0                   2.4                           1.05\n",
      "16  2022-07-01T00:00:00.000Z                      22.10                         79.0                   2.5                           7.55\n",
      "17  2022-06-25T00:00:00.000Z                      22.05                         60.0                   2.5                           0.20\n",
      "18  2020-06-17T00:00:00.000Z                      22.00                         58.0                   2.3                           0.30\n",
      "19  2020-06-26T00:00:00.000Z                      21.95                         60.0                   2.5                           0.05\n",
      "20  2020-06-25T00:00:00.000Z                      21.85                         68.0                   2.4                           0.00\n",
      "21  2021-07-17T00:00:00.000Z                      21.80                         51.0                   2.7                           0.00\n",
      "22  2023-06-14T00:00:00.000Z                      21.80                         45.0                   1.8                           0.00\n",
      "23  2022-07-21T00:00:00.000Z                      21.75                         78.0                   1.5                           0.10\n",
      "24  2021-07-02T00:00:00.000Z                      21.40                         42.0                   2.4                           0.20\n",
      "25  2020-06-13T00:00:00.000Z                      21.35                         38.0                   3.6                           0.00\n",
      "26  2020-06-12T00:00:00.000Z                      21.30                         37.0                   3.9                           0.00\n",
      "27  2024-05-26T00:00:00.000Z                      21.30                         62.0                   3.4                           0.45\n",
      "28  2020-06-15T00:00:00.000Z                      21.25                         41.0                   2.1                           0.00\n",
      "29  2020-06-28T00:00:00.000Z                      21.20                         88.0                   1.9                          13.15\n",
      "30  2021-07-24T00:00:00.000Z                      21.20                         55.0                   2.0                           0.00\n",
      "31  2024-07-21T00:00:00.000Z                      21.10                         67.0                   2.0                           0.00\n",
      "32  2023-07-09T00:00:00.000Z                      21.05                         57.0                   1.8                           0.00\n",
      "33  2024-06-28T00:00:00.000Z                      21.05                         79.0                   4.5                          16.40\n",
      "34  2021-07-23T00:00:00.000Z                      21.00                         52.0                   2.1                           0.00\n",
      "35  2023-07-10T00:00:00.000Z                      20.95                         69.0                   1.9                           0.05\n",
      "36  2022-06-26T00:00:00.000Z                      20.90                         86.0                   1.8                           7.65\n",
      "37  2024-06-27T00:00:00.000Z                      20.90                         63.0                   2.3                           0.00\n",
      "38  2024-06-02T00:00:00.000Z                      20.85                         62.0                   2.7                           0.15\n",
      "39  2020-06-24T00:00:00.000Z                      20.80                         70.0                   2.2                           0.00\n",
      "40  2024-06-01T00:00:00.000Z                      20.80                         66.0                   2.0                           5.05\n",
      "41  2022-07-20T00:00:00.000Z                      20.65                         65.0                   2.5                           0.00\n",
      "42  2023-06-29T00:00:00.000Z                      20.60                         80.0                   2.8                           0.05\n",
      "43  2020-06-14T00:00:00.000Z                      20.45                         40.0                   2.1                           0.00\n",
      "44  2023-06-28T00:00:00.000Z                      20.45                         65.0                   2.9                           0.00\n",
      "45  2023-06-26T00:00:00.000Z                      20.40                         78.0                   1.9                           3.15\n",
      "46  2021-07-13T00:00:00.000Z                      20.30                         54.0                   2.0                           0.00\n",
      "47  2023-06-24T00:00:00.000Z                      20.30                         53.0                   2.8                           0.00\n",
      "48  2023-06-13T00:00:00.000Z                      20.25                         47.0                   1.6                           0.00\n",
      "49  2023-06-25T00:00:00.000Z                      20.25                         67.0                   2.3                           0.00\n",
      "50  2021-07-05T00:00:00.000Z                      20.20                         72.0                   2.7                           8.75\n",
      "51  2021-07-18T00:00:00.000Z                      20.20                         44.0                   3.1                           0.00\n",
      "52  2024-05-23T00:00:00.000Z                      20.10                         45.0                   3.8                           0.00\n",
      "53  2020-06-21T00:00:00.000Z                      20.05                         83.0                   2.4                           8.45\n",
      "54  2021-07-22T00:00:00.000Z                      20.00                         65.0                   2.3                           0.00\n",
      "55  2024-07-22T00:00:00.000Z                      20.00                         92.0                   1.5                           6.55\n"
     ]
    }
   ],
   "source": [
    "query2=\"\"\"\n",
    "    SELECT * FROM df2\n",
    "    WHERE \"mean(air_temperature P1D)\">=20.0\n",
    "    ORDER BY \"mean(air_temperature P1D)\" DESC;\n",
    "\"\"\"\n",
    "resultat=pysqldf(query2)\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omgjøring av luftkvalitet-data til panda dataframe + forståelse: \n",
    "\n",
    "Her skal vi sortere gjennom luftkvalitetsdataen. Vi henter file-path og gjør om til data frame med pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import os\n",
    "\n",
    "# Henter file path\n",
    "\n",
    "notebook_directory = os.getcwd()\n",
    "root = os.path.abspath(os.path.join(notebook_directory, \"..\"))\n",
    "file_path_L = os.path.join(root, \"data\", \"luftkvalitet_Kirkeveien_all_years.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Først kan vi hente generell informasjon om det som ligger i filen, og lager en dataframe basert på geneerell info, som stasjon, område, hva vi måler og id: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       zone municipality  area     station component   unit  latitude  longitude                   dateTime      value  count  coverage\n",
      "0  21  Stor-Oslo         Oslo  Oslo  Kirkeveien       NO2  µg/m³  59.93231   10.72455  2020-04-01T00:00:00+01:00  22.176800     23        96\n",
      "1  21  Stor-Oslo         Oslo  Oslo  Kirkeveien       NO2  µg/m³  59.93231   10.72455  2020-04-02T00:00:00+01:00  12.066933     24       100\n",
      "2  21  Stor-Oslo         Oslo  Oslo  Kirkeveien       NO2  µg/m³  59.93231   10.72455  2020-04-03T00:00:00+01:00   5.252476     24       100\n",
      "3  21  Stor-Oslo         Oslo  Oslo  Kirkeveien       NO2  µg/m³  59.93231   10.72455  2020-04-04T00:00:00+01:00   9.445686     24       100\n",
      "4  21  Stor-Oslo         Oslo  Oslo  Kirkeveien       NO2  µg/m³  59.93231   10.72455  2020-04-05T00:00:00+01:00  15.043523     24       100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_path_L,\"r\") as fil: #leser filen og lagrer den som \"data\"\n",
    "    luftdata=json.load(fil)\n",
    "\n",
    "general_data = []\n",
    "for entry in luftdata:\n",
    "    # Extract general information\n",
    "    general_info = {\n",
    "        \"id\": entry.get(\"id\"),\n",
    "        \"zone\": entry.get(\"zone\"),\n",
    "        \"municipality\": entry.get(\"municipality\"),\n",
    "        \"area\": entry.get(\"area\"),\n",
    "        \"station\": entry.get(\"station\"),\n",
    "        \"component\": entry.get(\"component\"),\n",
    "        \"unit\": entry.get(\"unit\"),\n",
    "        \"latitude\": entry.get(\"latitude\"),\n",
    "        \"longitude\": entry.get(\"longitude\"),\n",
    "    }\n",
    "    \n",
    "    # Extract values (nested list of dictionaries)\n",
    "    for value in entry.get(\"values\", []):\n",
    "        # Combine general info with each value\n",
    "        row = general_info.copy()\n",
    "        row.update(value)  # Add fields from the \"values\" dictionary\n",
    "        general_data.append(row)\n",
    "\n",
    "# Create a DataFrame\n",
    "df1 = pd.DataFrame(general_data)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component       date        CO        NO        NO2        NOx       PM10      PM2.5\n",
      "0         2020-04-01  0.265466  6.311852  22.176800  31.821309  26.698062   7.374793\n",
      "1         2020-04-02  0.196590  2.667235  12.066933  16.142468  17.272707   4.935823\n",
      "2         2020-04-03  0.257888  2.052685   5.252476   8.388978  10.126831   1.303536\n",
      "3         2020-04-04  0.234627  2.732509   9.445686  13.620960  11.561105   3.290720\n",
      "4         2020-04-05  0.311696  2.664206  15.043523  19.114429  23.980191  15.100590\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "for entry in luftdata:\n",
    "    component = entry.get(\"component\")  # e.g., NO2, PM10, etc.\n",
    "    for value_entry in entry.get(\"values\", []):\n",
    "        # Extract date and value\n",
    "        processed_data.append({\n",
    "            \"date\": value_entry.get(\"dateTime\"),  # Assuming \"fromTime\" is the date field\n",
    "            \"component\": component,\n",
    "            \"value\": value_entry.get(\"value\")  # Assuming \"value\" is the observed value\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Pivot the DataFrame to have components as columns\n",
    "pivot_df = df.pivot(index=\"date\", columns=\"component\", values=\"value\")\n",
    "\n",
    "# Reset the index to make it easier to work with\n",
    "pivot_df.reset_index(inplace=True)\n",
    "pivot_df[\"date\"] = pd.to_datetime(pivot_df[\"date\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "\n",
    "print(pivot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lagrer filen som \"df1_data.json\"\n",
    "\n",
    "pivot_df.to_json('../data/df1_data.json',indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er et eksempel på bruk av sqldf for å hente data fra dataframe om luftkvalitet: \n",
    "\n",
    "- Total gjennomsnittlig verdi for de forskjellige partikkelmålingene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    avg_NO2   avg_PM10  avg_PM25    avg_CO    avg_NO    avg_NOx\n",
      "0  9.366441  11.309867  5.173862  0.195032  2.770652  13.599998\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        AVG(\"NO2\") AS avg_NO2,\n",
    "        AVG(\"PM10\") AS avg_PM10,\n",
    "        AVG(\"PM2.5\") AS avg_PM25,\n",
    "        AVG(\"CO\") AS avg_CO,\n",
    "        AVG(\"NO\") AS avg_NO,\n",
    "        AVG(\"NOx\") AS avg_NOx\n",
    "    FROM pivot_df\n",
    "\"\"\"\n",
    "result = pysqldf(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
